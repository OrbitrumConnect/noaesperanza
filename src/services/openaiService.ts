// Servi√ßo para comunica√ß√£o com OpenAI API
import { getNoaSystemPrompt } from '../config/noaSystemPrompt'
import { personalizedProfilesService } from './personalizedProfilesService'
import { loadNoaPrompt, logPromptInitialization } from './noaPromptLoader'

export interface ChatMessage {
  role: 'user' | 'assistant' | 'system'
  content: string
}

export interface OpenAIResponse {
  choices: Array<{
    message: {
      content: string
      role: string
    }
  }>
}

class OpenAIService {
  private apiKey: string
  private baseURL = 'https://api.openai.com/v1'
  private noaAgentId = 'asst_fN2Fk9fQ7JEyyFUIe50Fo9QD' // Agente espec√≠fico da NOA
  private fineTunedModel = 'ft:gpt-3.5-turbo-0125:personal:fine-tuning-noa-esperanza-avaliacao-inicial-dez-ex-jsonl:BR0W02VP' // Modelo fine-tuned da NOA

  constructor() {
    this.apiKey = import.meta.env.VITE_OPENAI_API_KEY
    if (!this.apiKey) {
      console.warn('OpenAI API Key n√£o encontrada - ativando modo offline')
    }
    
    // Log de inicializa√ß√£o do prompt mestre
    logPromptInitialization()
  }

  // M√©todo para usar modelo padr√£o (n√£o fine-tuned)
  async sendMessageWithStandardModel(
    messages: ChatMessage[], 
    systemPrompt?: string
  ): Promise<string> {
    try {
      const requestMessages: ChatMessage[] = []
      
      // Adiciona prompt do sistema se fornecido
      if (systemPrompt) {
        requestMessages.push({
          role: 'system',
          content: systemPrompt
        })
      }
      
      // Adiciona mensagens da conversa
      requestMessages.push(...messages)

      if (!this.apiKey) {
        return this.offlineResponse(messages)
      }

      const response = await fetch(`${this.baseURL}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify({
          model: 'gpt-3.5-turbo', // Usando modelo padr√£o
          messages: requestMessages,
          max_tokens: 1000,
          temperature: 0.7,
          stream: false
        })
      })

      if (!response.ok) {
        const errorData = await response.json()
        if (response.status === 401) {
          console.warn('OpenAI 401 - usando fallback offline')
          return this.offlineResponse(messages)
        }
        throw new Error(`OpenAI API Error: ${errorData.error?.message || 'Erro desconhecido'}`)
      }

      const data: OpenAIResponse = await response.json()
      
      if (data.choices && data.choices.length > 0) {
        return data.choices[0].message.content
      }
      
      throw new Error('Resposta vazia da OpenAI')
      
    } catch (error) {
      console.error('Erro ao comunicar com OpenAI:', error)
      return this.offlineResponse(messages)
    }
  }

  async sendMessage(
    messages: ChatMessage[], 
    systemPrompt?: string
  ): Promise<string> {
    try {
      const requestMessages: ChatMessage[] = []
      
      // Adiciona prompt do sistema se fornecido
      if (systemPrompt) {
        requestMessages.push({
          role: 'system',
          content: systemPrompt
        })
      }
      
      // Adiciona mensagens da conversa
      requestMessages.push(...messages)

      if (!this.apiKey) {
        return this.offlineResponse(messages)
      }

      const response = await fetch(`${this.baseURL}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify({
          model: 'gpt-3.5-turbo', // Usando modelo padr√£o em vez do fine-tuned
          messages: requestMessages,
          max_tokens: 1000,
          temperature: 0.7,
          stream: false
        })
      })

      if (!response.ok) {
        const errorData = await response.json()
        if (response.status === 401) {
          console.warn('OpenAI 401 - usando fallback offline')
          return this.offlineResponse(messages)
        }
        throw new Error(`OpenAI API Error: ${errorData.error?.message || 'Erro desconhecido'}`)
      }

      const data: OpenAIResponse = await response.json()
      
      if (data.choices && data.choices.length > 0) {
        return data.choices[0].message.content
      }
      
      throw new Error('Resposta vazia da OpenAI')
      
    } catch (error) {
      console.error('Erro ao comunicar com OpenAI:', error)
      return this.offlineResponse(messages)
    }
  }

  // M√©todo para usar o Assistants API com agente espec√≠fico
  async useNoaAgent(userMessage: string, threadId?: string): Promise<{ response: string, threadId: string }> {
    try {
      console.log('ü§ñ Usando agente NOA espec√≠fico:', this.noaAgentId)
      
      let currentThreadId = threadId
      
      // Criar thread se n√£o existir
      if (!currentThreadId) {
        const threadResponse = await fetch(`${this.baseURL}/threads`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${this.apiKey}`,
            'OpenAI-Beta': 'assistants=v2'
          },
          body: JSON.stringify({})
        })
        
        if (!threadResponse.ok) {
          throw new Error('Erro ao criar thread')
        }
        
        const threadData = await threadResponse.json()
        currentThreadId = threadData.id
        console.log('üßµ Thread criada:', currentThreadId)
      }
      
      // Adicionar mensagem do usu√°rio
      await fetch(`${this.baseURL}/threads/${currentThreadId}/messages`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`,
          'OpenAI-Beta': 'assistants=v2'
        },
        body: JSON.stringify({
          role: 'user',
          content: userMessage
        })
      })
      
      // Executar agente
      const runResponse = await fetch(`${this.baseURL}/threads/${currentThreadId}/runs`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`,
          'OpenAI-Beta': 'assistants=v2'
        },
        body: JSON.stringify({
          assistant_id: this.noaAgentId
        })
      })
      
      if (!runResponse.ok) {
        throw new Error('Erro ao executar agente')
      }
      
      const runData = await runResponse.json()
      console.log('üèÉ Run iniciado:', runData.id)
      
      // Aguardar conclus√£o
      let runStatus = 'in_progress'
      while (runStatus === 'in_progress' || runStatus === 'queued') {
        await new Promise(resolve => setTimeout(resolve, 1000))
        
        const statusResponse = await fetch(`${this.baseURL}/threads/${currentThreadId}/runs/${runData.id}`, {
          headers: {
            'Authorization': `Bearer ${this.apiKey}`,
            'OpenAI-Beta': 'assistants=v2'
          }
        })
        
        const statusData = await statusResponse.json()
        runStatus = statusData.status
        console.log('üìä Status do run:', runStatus)
      }
      
      if (runStatus !== 'completed') {
        throw new Error(`Run falhou com status: ${runStatus}`)
      }
      
      // Obter mensagens da thread
      const messagesResponse = await fetch(`${this.baseURL}/threads/${currentThreadId}/messages`, {
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,
          'OpenAI-Beta': 'assistants=v2'
        }
      })
      
      const messagesData = await messagesResponse.json()
      const lastMessage = messagesData.data[0] // √öltima mensagem √© a resposta do agente
      
      return {
        response: lastMessage.content[0].text.value,
        threadId: currentThreadId || ''
      }
      
    } catch (error) {
      console.error('Erro ao usar agente NOA:', error)
      // Fallback para m√©todo tradicional
      return {
        response: await this.getNoaResponseFallback(userMessage),
        threadId: ''
      }
    }
  }

  // M√©todo espec√≠fico para NOA - Assistente M√©dica com base de conhecimento pr√≥pria
  async getNoaResponse(userMessage: string, conversationHistory: ChatMessage[] = [], knowledgeBase?: string): Promise<string> {
    try {
      console.log('üéØ Usando modelo padr√£o com base de conhecimento pr√≥pria')
      
      // Verificar se h√° perfil ativo
      const activeProfile = personalizedProfilesService.getActiveProfile()
      
      // Construir prompt com sistema completo da N√¥a Esperanza V2.0
      let systemPrompt = ''
      
      if (activeProfile) {
        // Usar prompt personalizado do perfil
        systemPrompt = `${getNoaSystemPrompt({
          name: activeProfile.name,
          role: activeProfile.role,
          recognizedAs: activeProfile.name
        })}\n\n${activeProfile.systemPrompt}`
      } else {
        // Verificar formato antigo para compatibilidade
        try {
          const stored = localStorage.getItem('noa_recognized_user')
          if (stored) {
            const recognizedUser = JSON.parse(stored)
            systemPrompt = getNoaSystemPrompt({
              name: recognizedUser.name,
              role: recognizedUser.role,
              recognizedAs: recognizedUser.name
            })
          } else {
            systemPrompt = getNoaSystemPrompt({
              name: 'Usu√°rio',
              role: 'user'
            })
          }
        } catch (e) {
          console.warn('Erro ao carregar usu√°rio reconhecido:', e)
          systemPrompt = getNoaSystemPrompt({
            name: 'Usu√°rio',
            role: 'user'
          })
        }
      }

      // Adicionar base de conhecimento se fornecida
      if (knowledgeBase) {
        systemPrompt += `\n\nBASE DE CONHECIMENTO DA N√îA ESPERANZA:\n${knowledgeBase}\n\nIMPORTANTE: Use SEMPRE as informa√ß√µes da base de conhecimento acima. N√ÉO invente informa√ß√µes sobre "Weme" ou outras empresas.`
      }

      const messages: ChatMessage[] = [
        ...conversationHistory,
        {
          role: 'user',
          content: userMessage
        }
      ]

      // Usar modelo padr√£o em vez do fine-tuned externo
      return this.sendMessageWithStandardModel(messages, systemPrompt)
      
    } catch (error) {
      console.log('üîÑ Erro no modelo padr√£o, usando fallback')
      return this.getNoaResponseFallback(userMessage, conversationHistory)
    }
  }

  // M√©todo fallback tradicional
  private async getNoaResponseFallback(userMessage: string, conversationHistory: ChatMessage[] = []): Promise<string> {
    // Verificar se h√° perfil ativo
    const activeProfile = personalizedProfilesService.getActiveProfile()
    
    // Usar prompt do sistema V2.0
    let systemPrompt = ''
    
    if (activeProfile) {
      systemPrompt = `${getNoaSystemPrompt({
        name: activeProfile.name,
        role: activeProfile.role,
        recognizedAs: activeProfile.name
      })}\n\n${activeProfile.systemPrompt}`
    } else {
      try {
        const stored = localStorage.getItem('noa_recognized_user')
        if (stored) {
          const recognizedUser = JSON.parse(stored)
          systemPrompt = getNoaSystemPrompt({
            name: recognizedUser.name,
            role: recognizedUser.role,
            recognizedAs: recognizedUser.name
          })
        } else {
          systemPrompt = getNoaSystemPrompt({
            name: 'Usu√°rio',
            role: 'user'
          })
        }
      } catch (e) {
        console.warn('Erro ao carregar usu√°rio reconhecido:', e)
        systemPrompt = getNoaSystemPrompt({
          name: 'Usu√°rio',
          role: 'user'
        })
      }
    }

    const messages: ChatMessage[] = [
      ...conversationHistory,
      {
        role: 'user',
        content: userMessage
      }
    ]

    return this.sendMessage(messages, systemPrompt)
  }

  // üïê Fun√ß√£o para cumprimento baseado no hor√°rio
  private getTimeBasedGreeting(): string {
    const hour = new Date().getHours()
    if (hour >= 5 && hour < 12) return 'Bom dia'
    if (hour >= 12 && hour < 18) return 'Boa tarde'
    return 'Boa noite'
  }

  // Fallback inteligente offline
  private offlineResponse(messages: ChatMessage[]): string {
    const lastUser = [...messages].reverse().find(m => m.role === 'user')
    const userText = (lastUser?.content || '').toLowerCase().trim()
    const greeting = this.getTimeBasedGreeting()
    
    // Sauda√ß√µes
    if (userText.match(/^(oi|ol√°|ola|hey|bom dia|boa tarde|boa noite|e ai)/)) {
      return `${greeting}! Sou a N√¥a Esperanza üåø\n\nMuito prazer em conhec√™-lo! Estou aqui para ajudar com sua sa√∫de e bem-estar.\n\nPosso realizar avalia√ß√£o cl√≠nica completa, orientar sobre cannabis medicinal e muito mais.\n\nComo posso ajudar voc√™ hoje?`
    }
    
    // Como est√° / tudo bem
    if (userText.match(/(tudo bem|como (voc√™|vc|voce) est√°|como vai|legal|beleza)/)) {
      return `Estou √≥tima, muito obrigada por perguntar! üòä\n\nEstou aqui pronta para ajudar com o que voc√™ precisar. Seja para conversar sobre sua sa√∫de, fazer uma avalia√ß√£o cl√≠nica ou tirar d√∫vidas sobre tratamentos.\n\nE voc√™, como est√° se sentindo?`
    }
    
    // Quem √© / sobre voc√™
    if (userText.match(/(quem (√©|e) voc√™|quem (√©|e) noa|quem te criou|sobre voc√™|se apresente)/)) {
      return `Sou a N√¥a Esperanza, assistente m√©dica inteligente especializada em neurologia, cannabis medicinal e nefrologia. üß†üåø\n\nFui desenvolvida pelo Dr. Ricardo e sua equipe para oferecer atendimento humanizado e baseado em evid√™ncias cient√≠ficas.\n\nTenho conhecimento profundo em avalia√ß√£o cl√≠nica pelo protocolo IMRE e posso auxiliar em todo o processo terap√™utico.\n\nEst√° precisando de ajuda com algo espec√≠fico?`
    }
    
    // Avalia√ß√£o cl√≠nica
    if (userText.match(/(avalia|clinica|imre|consulta|sintoma|dor|problema)/)) {
      return `Entendo que voc√™ est√° buscando avalia√ß√£o cl√≠nica. Vou ajudar!\n\nRealizo uma avalia√ß√£o completa seguindo o protocolo IMRE (Identifica√ß√£o, Mol√©stia atual, Revis√£o de sistemas, Exame f√≠sico).\n\nPara come√ßarmos, me conte: qual √© a sua principal queixa ou preocupa√ß√£o de sa√∫de no momento?`
    }
    
    // Cannabis
    if (userText.match(/(cannabis|cbd|thc|oleo|canabidiol)/)) {
      return `Sobre cannabis medicinal, posso te orientar! üåø\n\nA cannabis tem se mostrado eficaz em diversas condi√ß√µes, especialmente dor cr√¥nica, ansiedade, ins√¥nia e condi√ß√µes neurol√≥gicas.\n\nPara prescri√ß√£o adequada, √© importante fazer uma avalia√ß√£o cl√≠nica completa. Assim consigo indicar o melhor produto, dosagem e forma de uso para o seu caso espec√≠fico.\n\nGostaria de come√ßar a avalia√ß√£o agora?`
    }
    
    // Tratamento / medicamento
    if (userText.match(/(tratamento|medicamento|remedio|prescri)/)) {
      return `Sobre tratamentos, trabalho de forma personalizada! üíä\n\nCada pessoa √© √∫nica e merece um plano terap√™utico individual. Posso orientar sobre medicamentos convencionais e cannabis medicinal.\n\nPara criar um plano adequado para voc√™, preciso conhecer melhor sua condi√ß√£o. Quer fazer uma avalia√ß√£o cl√≠nica comigo?`
    }
    
    // Ajuda / n√£o entendi
    if (userText.match(/(ajuda|help|socorro|perdid|n√£o entend)/)) {
      return `Estou aqui para ajudar! ü§ó\n\n**Principais funcionalidades:**\n‚Ä¢ Avalia√ß√£o cl√≠nica completa (IMRE)\n‚Ä¢ Orienta√ß√£o sobre cannabis medicinal\n‚Ä¢ Informa√ß√µes sobre tratamentos\n‚Ä¢ Acompanhamento terap√™utico\n\n√â s√≥ conversar comigo naturalmente! Pode fazer perguntas, contar seus sintomas ou pedir orienta√ß√µes.\n\nSobre o que gostaria de conversar?`
    }
    
    // üí¨ CONVERSA√á√ÉO LIVRE - Respostas naturais e emp√°ticas
    const conversationHistory = messages.map(m => m.content).join(' ').toLowerCase()
    
    // Detectar t√≥picos de interesse
    const topicos = {
      saude: /sa√∫de|bem.?estar|cuidar|preven√ß√£o|qualidade de vida/,
      emocional: /ansiedade|depress√£o|estresse|medo|preocupa|triste|nervos/,
      sono: /sono|ins√¥nia|dormir|acordar|cansa√ßo/,
      alimentacao: /comer|dieta|alimenta√ß√£o|nutri|peso|emagrecer/,
      exercicio: /exerc√≠cio|academia|corrida|caminhada|atividade f√≠sica/,
      curiosidade: /por.?que|como.?funciona|explica|entender|saber/,
      agradecimento: /obrigad|valeu|legal|massa|show|obg|vlw/,
      casual: /rs|kk|kkk|haha|üòÇ|üòä|legal|massa|bacana/
    }
    
    // Agradecimento
    if (topicos.agradecimento.test(userText)) {
      const respostasAgradecimento = [
        `Por nada! üòä Estou sempre aqui para ajudar. Precisa de mais alguma coisa?`,
        `Fico feliz em ajudar! üåø Pode contar comigo sempre que precisar.`,
        `√â um prazer poder te ajudar! Qualquer d√∫vida, √© s√≥ chamar.`
      ]
      return respostasAgradecimento[Math.floor(Math.random() * respostasAgradecimento.length)]
    }
    
    // Emocional
    if (topicos.emocional.test(userText)) {
      return `Entendo... quest√µes emocionais afetam muito nossa sa√∫de f√≠sica tamb√©m. üíô\n\n√â importante cuidar tanto do corpo quanto da mente. A cannabis medicinal pode ajudar em casos de ansiedade e estresse, por exemplo.\n\nGostaria de conversar mais sobre isso? Ou prefere fazer uma avalia√ß√£o para eu entender melhor sua situa√ß√£o?`
    }
    
    // Sono
    if (topicos.sono.test(userText)) {
      return `Sono de qualidade √© fundamental para a sa√∫de! üò¥\n\nProblemas de sono podem estar relacionados a diversos fatores: estresse, ansiedade, h√°bitos, dor cr√¥nica...\n\nExistem op√ß√µes tanto de higiene do sono quanto terap√™uticas (incluindo cannabis medicinal para ins√¥nia).\n\nQuer que eu te ajude a entender melhor o seu caso?`
    }
    
    // Alimenta√ß√£o
    if (topicos.alimentacao.test(userText)) {
      return `Alimenta√ß√£o √© mesmo muito importante! ü•ó\n\nNutri√ß√£o adequada impacta diretamente na sa√∫de, energia, humor e at√© no sistema imunol√≥gico.\n\nEmbora minha especialidade seja mais cl√≠nica e medicinal, posso te orientar sobre como a alimenta√ß√£o se relaciona com sua sa√∫de geral.\n\nGostaria de conversar sobre alguma condi√ß√£o espec√≠fica ou fazer uma avalia√ß√£o?`
    }
    
    // Exerc√≠cio
    if (topicos.exercicio.test(userText)) {
      return `Atividade f√≠sica √© maravilhosa para a sa√∫de! üí™\n\nExerc√≠cios regulares ajudam com circula√ß√£o, humor, sono, controle de doen√ßas cr√¥nicas e muito mais.\n\nImportante sempre adaptar a atividade √† sua condi√ß√£o de sa√∫de. Tem alguma limita√ß√£o ou quest√£o que devo saber?`
    }
    
    // Curiosidade / Perguntas gerais
    if (topicos.curiosidade.test(userText)) {
      return `√ìtima pergunta! Adoro quando as pessoas querem entender melhor as coisas. ü§ì\n\nTenho conhecimento em neurologia, nefrologia, cannabis medicinal e avalia√ß√£o cl√≠nica geral.\n\nPoderia reformular sua pergunta de forma mais espec√≠fica? Assim consigo te dar uma resposta mais completa e √∫til!`
    }
    
    // Casual / Descontra√≠do
    if (topicos.casual.test(userText)) {
      const respostasCasuais = [
        `Haha, gosto dessa energia! üòÑ Vamos conversar? Sobre o que voc√™ quer saber?`,
        `Legal mesmo! üòä Estou aqui para o que precisar. Pode perguntar √† vontade!`,
        `Que bom! üåø Vamos aproveitar para conversar sobre sua sa√∫de ou tirar alguma d√∫vida?`
      ]
      return respostasCasuais[Math.floor(Math.random() * respostasCasuais.length)]
    }
    
    // Fallback SUPER natural - Resposta conversacional livre
    const respostasLivres = [
      `Entendi! Sobre isso, posso te ajudar de algumas formas. Quer que eu explique mais sobre o tema ou prefere fazer perguntas espec√≠ficas?`,
      
      `Interessante voc√™ perguntar sobre isso! üåø Tenho bastante conhecimento em sa√∫de e medicina. Me conta mais, estou curiosa para entender melhor sua situa√ß√£o.`,
      
      `Certo! Vamos explorar isso juntos. O que exatamente voc√™ gostaria de saber ou resolver? Pode falar livremente!`,
      
      `Ah, entendo o que voc√™ est√° dizendo. Deixa eu pensar na melhor forma de te ajudar... Voc√™ est√° com alguma preocupa√ß√£o espec√≠fica ou √© mais uma curiosidade?`,
      
      `Legal! Adoro quando as pessoas se interessam por sa√∫de. üòä Pode me contar mais detalhes? Quanto mais eu souber, melhor posso te orientar.`
    ]
    
    return respostasLivres[Math.floor(Math.random() * respostasLivres.length)]
  }
}

export const openAIService = new OpenAIService()

// üåÄ GPT BUILDER V2 - ENVIAR PARA OPENAI
// Envia prompt completo para GPT-4o com configura√ß√µes otimizadas
export async function sendToOpenAI(fullPrompt: string) {
  const apiKey = import.meta.env.VITE_OPENAI_API_KEY
  
  const response = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "Authorization": `Bearer ${apiKey}`
    },
    body: JSON.stringify({
      model: "gpt-4o",
      messages: [
        { role: "system", content: "Voc√™ √© N√¥a Esperanza, assistente cl√≠nica da plataforma, com base simb√≥lica e escuta ativa." },
        { role: "user", content: fullPrompt }
      ],
      temperature: 0.7
    })
  });

  const data = await response.json();
  return data.choices[0].message.content;
}
